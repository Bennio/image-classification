
# First we copy the values of values.yaml in variable to make it easier to access them
{{- $lrlist := .Values.hyperParamValues.learning_rate -}}
{{- $batchsizelist := .Values.hyperParamValues.train_batch_size -}}
{{- $image := .Values.container.image -}}
{{- $name := .Values.tfjob.name -}}
{{- $pvc := .Values.container.pvcName -}}
{{- $subPath := .Values.container.subPath -}}
{{- $useGPU := .Values.tfjob.useGPU -}}
{{- $chartname := .Chart.Name -}}
{{- $chartversion := .Chart.Version -}}

# Then we loop over every value of $lrlist (learning rate) and $batchsize (train batch size)
# This will result in create 1 TFJob for every pair of learning rate and train batch size
{{- range $i, $lr := $lrlist }}
{{- range $j, $batchsize := $batchsizelist }}
apiVersion: kubeflow.org/v1beta1
kind: TFJob # Each one of our trainings will be a separate TFJob
metadata:
  name: {{ $name }}-{{ $i }}-{{ $j }} # We give a unique name to each training
  labels:
    chart: "{{ $chartname }}-{{ $chartversion | replace "+" "_" }}"
spec: 
  tfReplicaSpecs:
    MASTER:
      template:
        spec:
          containers:
            - name: tensorflow
              image: {{ $image }}
              args:
                # Here we pass a unique learning rate and batch size to each instance.
                # We also put the values between quotes to avoid potential formatting issues    
                # We save the output in a different directory for each pod
                - "--bottleneck_dir=bottlenecks"
                - "--model_dir=/tf-output/image-retraining-lr{{ $lr }}-bs-{{ $batchsize }}/inception"
                - "--summaries_dir=/tf-output/training_summaries/image-retraining-lr{{ $lr }}-bs-{{ $batchsize }}/baseline"
                - "--output_graph=/tf-output/image-retraining-lr{{ $lr }}-bs-{{ $batchsize }}/retrained_graph.pb"
                - "--output_labels=/tf-output/image-retraining-lr{{ $lr }}-bs-{{ $batchsize }}/retrained_labels.txt"
                - "--image_dir=images"
                - "--learning_rate"
                - {{ $lr | quote }}
                - "--train_batch_size"
                - {{ $batchsize | quote }}
{{ if $useGPU }}  # We only want to request GPUs if we asked for it in values.yaml with useGPU
              resources:
                limits:
                  nvidia.com/gpu: 1
{{ end }}
              volumeMounts:
              - mountPath: /tf-output
                subPath: {{ $subPath }}
                name: {{ $pvc }}
          volumes:
            - name: {{ $pvc }}
              persistentVolumeClaim:
                claimName: {{ $pvc }}
---
{{- end }}
{{- end }}